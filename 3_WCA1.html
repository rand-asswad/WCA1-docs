<!DOCTYPE html>
<html lang="en-US" xml:lang="en-US">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Sound reconstruction model | A bio-inspired geometric model for sound reconstruction</title>
  <meta name="description" content="3 Sound reconstruction model | A bio-inspired geometric model for sound reconstruction" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Sound reconstruction model | A bio-inspired geometric model for sound reconstruction" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rand-asswad/WCA1-docs" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Sound reconstruction model | A bio-inspired geometric model for sound reconstruction" />
  
  
  

<meta name="author" content="Rand ASSWAD" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="2_WCV1.html"/>
<link rel="next" href="4_implementation.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="include/gitbook.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="https://www.insa-rouen.fr/" target="_blank"><img src="img/logo_insa.png"></a></li>
<li class="toc-title"><a href="./">A bio-geometric model for sound reconstruction</a></li>
<li class="toc-author"><a href="/" target="_blank">Rand ASSWAD</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="0_pre_intro.html"><a href="0_pre_intro.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="1" data-path="1_intro.html"><a href="1_intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1_intro.html"><a href="1_intro.html#laboratory-and-supervision"><i class="fa fa-check"></i><b>1.1</b> Laboratory and supervision</a></li>
<li class="chapter" data-level="1.2" data-path="1_intro.html"><a href="1_intro.html#internship-mission"><i class="fa fa-check"></i><b>1.2</b> Internship mission</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2_WCV1.html"><a href="2_WCV1.html"><i class="fa fa-check"></i><b>2</b> Image reconstruction model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2_WCV1.html"><a href="2_WCV1.html#neoro-geometric-model-of-v1"><i class="fa fa-check"></i><b>2.1</b> Neoro-geometric model of V1</a></li>
<li class="chapter" data-level="2.2" data-path="2_WCV1.html"><a href="2_WCV1.html#wilson-cowan-model-in-v1"><i class="fa fa-check"></i><b>2.2</b> Wilson-Cowan model in V1</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3_WCA1.html"><a href="3_WCA1.html"><i class="fa fa-check"></i><b>3</b> Sound reconstruction model</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3_WCA1.html"><a href="3_WCA1.html#from-v1-to-a1"><i class="fa fa-check"></i><b>3.1</b> From V1 to A1</a></li>
<li class="chapter" data-level="3.2" data-path="3_WCA1.html"><a href="3_WCA1.html#sound-reconstruction-pipeline"><i class="fa fa-check"></i><b>3.2</b> Sound reconstruction pipeline</a></li>
<li class="chapter" data-level="3.3" data-path="3_WCA1.html"><a href="3_WCA1.html#time-frequency-representation"><i class="fa fa-check"></i><b>3.3</b> Time-Frequency representation</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="3_WCA1.html"><a href="3_WCA1.html#the-short-time-fourier-transform"><i class="fa fa-check"></i><b>3.3.1</b> The Short-Time Fourier Transform</a></li>
<li class="chapter" data-level="3.3.2" data-path="3_WCA1.html"><a href="3_WCA1.html#time-and-frequency-shifts-operators"><i class="fa fa-check"></i><b>3.3.2</b> Time and frequency shifts operators</a></li>
<li class="chapter" data-level="3.3.3" data-path="3_WCA1.html"><a href="3_WCA1.html#discrete-stft"><i class="fa fa-check"></i><b>3.3.3</b> Discrete STFT</a></li>
<li class="chapter" data-level="3.3.4" data-path="3_WCA1.html"><a href="3_WCA1.html#stft-windowing"><i class="fa fa-check"></i><b>3.3.4</b> STFT windowing</a></li>
<li class="chapter" data-level="3.3.5" data-path="3_WCA1.html"><a href="3_WCA1.html#uncertainty-principle-and-resolution-issues"><i class="fa fa-check"></i><b>3.3.5</b> Uncertainty principle and resolution issues</a></li>
<li class="chapter" data-level="3.3.6" data-path="3_WCA1.html"><a href="3_WCA1.html#inverse-short-time-fourier-transform"><i class="fa fa-check"></i><b>3.3.6</b> Inverse Short-Time Fourier Transform</a></li>
<li class="chapter" data-level="3.3.7" data-path="3_WCA1.html"><a href="3_WCA1.html#griffin-lim-algorithm"><i class="fa fa-check"></i><b>3.3.7</b> Griffin-Lim Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3_WCA1.html"><a href="3_WCA1.html#the-lift-to-the-augmented-space"><i class="fa fa-check"></i><b>3.4</b> The lift to the augmented space</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="3_WCA1.html"><a href="3_WCA1.html#the-sound-chirpiness"><i class="fa fa-check"></i><b>3.4.1</b> The sound chirpiness</a></li>
<li class="chapter" data-level="3.4.2" data-path="3_WCA1.html"><a href="3_WCA1.html#single-time-varying-frequency"><i class="fa fa-check"></i><b>3.4.2</b> Single time-varying frequency</a></li>
<li class="chapter" data-level="3.4.3" data-path="3_WCA1.html"><a href="3_WCA1.html#control-system"><i class="fa fa-check"></i><b>3.4.3</b> Control system</a></li>
<li class="chapter" data-level="3.4.4" data-path="3_WCA1.html"><a href="3_WCA1.html#lift-to-the-contact-space"><i class="fa fa-check"></i><b>3.4.4</b> Lift to the contact space</a></li>
<li class="chapter" data-level="3.4.5" data-path="3_WCA1.html"><a href="3_WCA1.html#lift-implementation"><i class="fa fa-check"></i><b>3.4.5</b> Lift implementation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="3_WCA1.html"><a href="3_WCA1.html#cortical-activations-in-a1"><i class="fa fa-check"></i><b>3.5</b> Cortical activations in A1</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4_implementation.html"><a href="4_implementation.html"><i class="fa fa-check"></i><b>4</b> Implementation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4_implementation.html"><a href="4_implementation.html#the-wca1.jl-library"><i class="fa fa-check"></i><b>4.1</b> The <code>WCA1.jl</code> library</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="4_implementation.html"><a href="4_implementation.html#the-stft-module"><i class="fa fa-check"></i><b>4.1.1</b> The STFT module</a></li>
<li class="chapter" data-level="4.1.2" data-path="4_implementation.html"><a href="4_implementation.html#optimizing-the-lift-module"><i class="fa fa-check"></i><b>4.1.2</b> Optimizing the lift module</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4_implementation.html"><a href="4_implementation.html#results"><i class="fa fa-check"></i><b>4.2</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5_conclusion.html"><a href="5_conclusion.html"><i class="fa fa-check"></i><b>5</b> Conclusion</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5_conclusion.html"><a href="5_conclusion.html#reviewing-the-model"><i class="fa fa-check"></i><b>5.1</b> Reviewing the model</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="5_conclusion.html"><a href="5_conclusion.html#model-analysis"><i class="fa fa-check"></i><b>5.1.1</b> Model analysis</a></li>
<li class="chapter" data-level="5.1.2" data-path="5_conclusion.html"><a href="5_conclusion.html#wavelet-transform"><i class="fa fa-check"></i><b>5.1.2</b> Wavelet transform</a></li>
<li class="chapter" data-level="5.1.3" data-path="5_conclusion.html"><a href="5_conclusion.html#the-lift-operator"><i class="fa fa-check"></i><b>5.1.3</b> The lift operator</a></li>
<li class="chapter" data-level="5.1.4" data-path="5_conclusion.html"><a href="5_conclusion.html#the-group-representation"><i class="fa fa-check"></i><b>5.1.4</b> The group representation</a></li>
<li class="chapter" data-level="5.1.5" data-path="5_conclusion.html"><a href="5_conclusion.html#the-wca1.jl-package"><i class="fa fa-check"></i><b>5.1.5</b> The <code>WCA1.jl</code> package</a></li>
<li class="chapter" data-level="5.1.6" data-path="5_conclusion.html"><a href="5_conclusion.html#a-sparse-lift-implementation"><i class="fa fa-check"></i><b>5.1.6</b> A sparse lift implementation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="5_conclusion.html"><a href="5_conclusion.html#acquired-knowledge"><i class="fa fa-check"></i><b>5.2</b> Acquired knowledge</a></li>
<li class="chapter" data-level="5.3" data-path="5_conclusion.html"><a href="5_conclusion.html#my-future-project"><i class="fa fa-check"></i><b>5.3</b> My future project</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="6A_stft.html"><a href="6A_stft.html"><i class="fa fa-check"></i><b>A</b> Short-Time Fourier Transform</a>
<ul>
<li class="chapter" data-level="A.1" data-path="6A_stft.html"><a href="6A_stft.html#parsevals-formula"><i class="fa fa-check"></i><b>A.1</b> Parseval’s formula</a></li>
<li class="chapter" data-level="A.2" data-path="6A_stft.html"><a href="6A_stft.html#inverse-short-time-fourier-transform-1"><i class="fa fa-check"></i><b>A.2</b> Inverse Short-Time Fourier Transform</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="6B_uncertainty.html"><a href="6B_uncertainty.html"><i class="fa fa-check"></i><b>B</b> Uncertainty principle</a></li>
<li class="chapter" data-level="C" data-path="6C_heisenberg.html"><a href="6C_heisenberg.html"><i class="fa fa-check"></i><b>C</b> Heisenberg group</a>
<ul>
<li class="chapter" data-level="C.1" data-path="6C_heisenberg.html"><a href="6C_heisenberg.html#heisenberg-group-action-on-the-contact-space"><i class="fa fa-check"></i><b>C.1</b> Heisenberg group action on the contact space</a></li>
<li class="chapter" data-level="C.2" data-path="6C_heisenberg.html"><a href="6C_heisenberg.html#introducing-the-chirpiness-to-the-heisenberg-group"><i class="fa fa-check"></i><b>C.2</b> Introducing the chirpiness to the Heisenberg group</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="7_refs.html"><a href="7_refs.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="book.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF book</a></li>
<li><a href="onepage.html" target="_blank"><i class="fa fa-file-code-o"></i> HTML standalone version</a></li>
<li><a href="presentation.pdf" target="_blank"><img class="icon" src="include/presentation.svg"> Presentation slides</a></li>
<li><a href="https://github.com/rand-asswad/WCA1" target="_blank"><i class="fa fa-github"></i> Github repository</a></li>
<li><a href="https://github.com/rand-asswad/WCA1/archive/refs/heads/master.zip"><i class="fa fa-download"></i> Download source code</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A bio-inspired geometric model for sound reconstruction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sound-reconstruction-model" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Sound reconstruction model</h1>
<div id="from-v1-to-a1" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> From V1 to A1</h2>
<p>The motivation behind the application of the model in sound reconstruction
is the idea that a sound can be seen as an image in the time-frequency domain.
The primary auditory cortex A1 receives the sensory input directly from the cochlea <span class="citation">[<a href="#ref-dallos1996" role="doc-biblioref">12</a>]</span>,
which is a spiral-shaped fluid-filled cavity that composes the inner ear.</p>
<p>The mechanical vibrations along the basilar membrane are transduced into electrical activity
along a dense, topographically ordered, array of auditory-nerve fibers
which convey these electrical potentials to the central auditory system.</p>
<p>Since these auditory-nerve fibers (sensors or inner hair cells) are topographically ordered
along the cochlea spiral, different regions of the cochlea are sensitive to different frequencies.
Hair cells close to the base are more sensitive to low-frequency sounds and those near the apex
are more sensitive to high-frequency sounds <span class="citation">[<a href="#ref-yang1992" role="doc-biblioref">28</a>]</span>.</p>
<div class="figure">
<img src="img/cochlea.png" style="width:50.0%" alt="" />
<p class="caption">Perceived pitch of a sound depends on the location in the cochlea that the sound wave stimulated <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
</div>
<p>This spatial segregation of frequency sensitivity in the cochlea
means that the primary auditory cortex receives a time-frequency representation of the sound.
In this model, we consider the Short-Time Fourier Transform (STFT)
as the time-frequency representation <span class="math inline">\(S(\tau,\omega)\)</span> of a sound signal <span class="math inline">\(s\in L^2(\mathbb{R})\)</span></p>
<p>While the spectrogram of a sound signal <span class="math inline">\(\left\lvert S\right\rvert(\tau,\omega)\)</span> is an image,
the image reconstruction algorithm cannot be applied to a corrupted sound
since the rotated spectrogram would correspond to completely different input sound
therefore the invariance by rototranslation is lost.
Moreover, the image reconstruction would evolve the WC equation on the entire
image simultaneously. However, the sound image (spectrogram) does not reach
the auditory cortex simultaneously but sequentially.
Hence, the reconstruction can be performed only in a sliding window <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
</div>
<div id="sound-reconstruction-pipeline" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Sound reconstruction pipeline</h2>
<p>As discussed in the previous section, the sound reconstruction model
is inspired by the V1 model.
First, a 2-dimensional image of the sound signal is obtained via a short-time Fourier transform,
which is analogous to the spectrogram the cochlea transmits to the auditory cortex.
The time derivative of the frequency <span class="math inline">\(\nu=\mathrm{d}\omega/\mathrm{d}\tau\)</span>, corresponding to the chirpiness of the sound,
allows adding a new dimension to the sound image.
Afterwards, the sound image is lifted into an <em>augmented space</em> that is <span class="math inline">\(\mathbb{R}^3\)</span>
with the Heisenberg group structure.
Henceforth, the sound is processed in its 3D representation,
that is the obtained lift <span class="math inline">\(L(\tau,\omega,\nu)\)</span>.</p>
<p>Similarly to the V1 model, the sound is reconstructed by solving
the Wilson-Cowan integro-differential equation.</p>
<p>Finally, the solution to the Wilson-Cowan equations is projected into
the time-frequency representation which gives a sound signal through
an inverse short-time Fourier transform <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
<div class="figure">
<img src="img/pipeline.png" style="width:70.0%" alt="" />
<p class="caption">Sound reconstruction pipeline</p>
</div>
</div>
<div id="time-frequency-representation" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Time-Frequency representation</h2>
<p>The Fourier transform transforms a time signal <span class="math inline">\(s\in L^2(\mathbb{R})\)</span>
into a complex function of frequency <span class="math inline">\(\hat s\in L^2(\mathbb{R})\)</span>.
Since the time signal <span class="math inline">\(s\)</span> can be obtained from <span class="math inline">\(\hat s\)</span>
using the Inverse Fourier Transform, they both contain
the exact same information.
Conceptually, <span class="math inline">\(s\)</span> and <span class="math inline">\(\hat s\)</span> can be considered two equivalent
representations of the same object <span class="math inline">\(s\)</span>, but each one
makes visible different features of <span class="math inline">\(s\)</span>.</p>
<p>A time-frequency representation would combine the features
of both <span class="math inline">\(s\)</span> and <span class="math inline">\(\hat s\)</span> into a single function.
Such representation provides an <em>instantaneous frequency spectrum</em>
of the signal at any given time <span class="citation">[<a href="#ref-grochenig2001" role="doc-biblioref">15</a>]</span>.</p>
<div id="the-short-time-fourier-transform" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> The Short-Time Fourier Transform</h3>
<p>The Short-Time Fourier Transform (STFT) is a very common
Time-Frequency representation of a signal.
The principle of the STFT is quite straightforward.
In order to obtain a Time-Frequency representation of a signal <span class="math inline">\(s\)</span>,
a Fourier transform is taken over a restricted interval
of the original signal <em>sequentially</em>.
Since a sharp cut-off introduces discontinuities and aliasing issues,
a smooth cut-off is prefered <span class="citation">[<a href="#ref-grochenig2001" role="doc-biblioref">15</a>]</span>.
This is established by multiplying a segment of the signal by a weight function,
that is smooth, compactly supported, and centered around <span class="math inline">\(0\)</span>,
referred to as <em>window</em>.
Essentially, the STFT <span class="math inline">\(S(\tau,\omega)\)</span> is the Fourier transform of <span class="math inline">\(s(t)w(t-\tau)\)</span>
(the signal taken over a sliding window along the time axis.)</p>
<p><span class="math display">\[\begin{equation}
S(\tau,\omega) = \int_\mathbb{R}s(t)w(t-\tau)e^{-2\pi i\omega t} \mathrm{d}t
\end{equation}\]</span></p>
<div class="figure">
<img src="img/stft_grochenig.png" style="width:37.0%" alt="" />
<p class="caption">Signal windowing for the STFT <span class="citation">[<a href="#ref-grochenig2001" role="doc-biblioref">15</a>]</span></p>
</div>
</div>
<div id="time-and-frequency-shifts-operators" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Time and frequency shifts operators</h3>
<p>In our study, we consider realizable signals <span class="math inline">\(s\in L^2(\mathbb{R})\)</span>.
Fundamental operators in time-frequency analysis are
time and phase shifts acting on realizable signals <span class="math inline">\(s\in L^2(\mathbb{R})\)</span>.</p>
<ul>
<li><strong>Time shift operator:</strong> <span class="math inline">\(T_\tau s(t)=s(t-\tau)\)</span></li>
<li><strong>Phase shift operator:</strong> <span class="math inline">\(M_\omega s(t)=e^{2\pi i \omega t} s(t)\)</span></li>
</ul>
<p>We notice that the STFT can be formulated using these unitary operators</p>
<p><span class="math display">\[\begin{align}
S(\tau,\omega) &amp;= \int_\mathbb{R}s(t)w(t-\tau)e^{-2\pi i\omega t} \mathrm{d}t\\
    &amp;= \int_\mathbb{R}s(t) \overline{M_\omega T_\tau w(t)} \mathrm{d}t\\
    &amp;= \left\langle s, M_\omega T_\tau w\right\rangle_{L^2(\mathbb{R})}
\end{align}\]</span></p>
<p>We can redefine the STFT as an operator <span class="math inline">\(V_w\)</span> on <span class="math inline">\(s\in L^2(\mathbb{R})\)</span>
defined in function of <span class="math inline">\(T_\tau\)</span> and <span class="math inline">\(M_\omega\)</span> <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>,<a href="#ref-grochenig2001" role="doc-biblioref">15</a>]</span>.</p>
<p><span class="math display">\[\begin{equation}\label{eq:stft_operator}
V_w s(\tau,\omega) = \left\langle s, M_\omega T_\tau w\right\rangle_{L^2(\mathbb{R})}
\end{equation}\]</span></p>
</div>
<div id="discrete-stft" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Discrete STFT</h3>
<p>Similarly to the continuous STFT, the discrete STFT is the
Discrete Fourier Transform (DFT) of the signal over a sliding window.
Nevertheless, the window cannot slide continuously along the time axis,
instead the signal is windowed at different frames with an overlap.
The window therefore hops along the time axis.</p>
<p>Let <span class="math inline">\(N\)</span> be the window size (DFT size), we define the overlap <span class="math inline">\(R\)</span>
as the number of overlapping frames between two consecutive windows.
The hop size is therefore defined as <span class="math inline">\(H=N-R\)</span>.
We also define the overlap ratio as the ratio of the overlap
with respect to the window size <span class="math inline">\(r=R/N\)</span> where <span class="math inline">\(r\in[0,1[\)</span>.</p>
<p>The discrete STFT of a signal <span class="math inline">\(s\in L^2([0,T])\)</span> is therefore
<span class="math display">\[\begin{equation}
S[m,\omega] = \sum_{t=0}^{T} s[t]w[t-mH]e^{-2\pi i\omega t}
\end{equation}\]</span></p>
<p>The choice of parameters has direct influence over the discrete STFT
resolution, as well as its invertibility.</p>
</div>
<div id="stft-windowing" class="section level3" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> STFT windowing</h3>
<p>The choice of the window affects quality of the Fourier transform.
One should choose a window with anti-aliasing and that distributes
spectral leakage.</p>
<div class="figure">
<img src="img/w_rectangle.png" alt="" />
<p class="caption">(a) Rectangular window</p>
</div>
<div class="figure">
<img src="img/w_triangle.png" alt="" />
<p class="caption">(b) Triangular window</p>
</div>
<div class="figure">
<img src="img/w_hann.png" alt="" />
<p class="caption">(c) Hann window</p>
</div>
<p class="caption">
Different windows (left) and their respective Fourier transform (right)
</p>
<p>Moreover, as we will see in the next sections, the STFT is invertible.
However, the STFT parameters need to satisfy the two following constraints <span class="citation">[<a href="#ref-griffin1983" role="doc-biblioref">14</a>,<a href="#ref-muller2015" role="doc-biblioref">21</a>]</span>:</p>
<ul>
<li><strong>Nonzero OverLap Add (NOLA):</strong> <span class="math inline">\(\sum\limits_{m\in\mathbb{Z}} w^2[t-mH] \neq 0\)</span></li>
<li><strong>Constant OverLap Add (COLA):</strong> <span class="math inline">\(\sum\limits_{m\in\mathbb{Z}} w[t-mH] = 1\)</span></li>
</ul>
<p>The NOLA condition is met for any window given an overlap ratio <span class="math inline">\(r\in[0,1[\)</span>.
It is worth noting that this condition can be found without the square
depending on the inverse STFT algorithm.</p>
<p>The COLA constraint defines the partition of unity over the discrete time axis,
imposing a stronger condition.</p>
<div class="figure">
<img src="img/woa_triangular_1_2.png" alt="" />
<p class="caption">(a) Triangular window, overlap ratio <span class="math inline">\(r=\frac{1}{2}\)</span></p>
</div>
<div class="figure">
<img src="img/woa_hann_1_2.png" alt="" />
<p class="caption">(b) Hann window, overlap ratio <span class="math inline">\(r=\frac{1}{2}\)</span></p>
</div>
<div class="figure">
<img src="img/woa_hann_3_8.png" alt="" />
<p class="caption">(c) Hann window, overlap ratio <span class="math inline">\(r=\frac{3}{8}\)</span></p>
</div>
<p class="caption">
The COLA condition with different windows and overlap ratios
</p>
<p>In typical applications, the window functions used are non-negative,
smooth, bell-shaped curves <span class="citation">[<a href="#ref-roads2002" role="doc-biblioref">25</a>]</span>.
A comprehensive list of windows and their properties may be found in <span class="citation">[<a href="#ref-heinzel2002" role="doc-biblioref">16</a>]</span>.
In our model we use the Hann window, which satisfies the COLA condition
for any overlap ratio of <span class="math inline">\(r=\frac{n}{n+1},n\in\mathbb{N}^*\)</span>.</p>
<p>The Hann window of length <span class="math inline">\(L\)</span> is defined as
<span class="math display">\[\begin{equation}
w(x)=\begin{cases}
\frac{1+\cos\left(\frac{2\pi x}{L}\right)}{2} &amp; \text{if}~\left\lvert x\right\rvert\leq\frac{L}{2}\\
0 &amp; \text{if}~\left\lvert x\right\rvert&gt;\frac{L}{2}
\end{cases}
\end{equation}\]</span></p>
</div>
<div id="uncertainty-principle-and-resolution-issues" class="section level3" number="3.3.5">
<h3><span class="header-section-number">3.3.5</span> Uncertainty principle and resolution issues</h3>
<p>As previously stated, both <span class="math inline">\(s\)</span> and <span class="math inline">\(\hat s\)</span> contain the exact same information.
However, there is a fundamental limit to the accuracy with which the values
for certain pairs of physical pairs can be observed.
A known example to issue is Heisenberg’s uncertainty principle regarding
the position of a particle and its momentum <span class="citation">[<a href="#ref-sen2014" role="doc-biblioref">26</a>]</span>.
Similarly, time and frequency are a pair of complementary variables.</p>
<p>In the context of time-frequency analysis, the Heisenberg-Gabor limit
(or simply the Gabor limit) defines this constraint by the following inequality
(proof in Appendix <a href="6B_uncertainty.html#uncertainty">B</a>)</p>
<p><span class="math display">\[\begin{equation}
\sigma_t\cdot\sigma_\omega\geq \frac{1}{4\pi}
\end{equation}\]</span>
where <span class="math inline">\(\sigma_t\)</span> and <span class="math inline">\(\sigma_\omega\)</span> are the standard deviations of the time and frequency respectively.</p>
<p>The Gabor limit means essentially that
“a realizable signal occupies a region of area at least one in the time-frequency plane.”
Which means that we cannot sharply localize a signal in both the time domain and frequency domain.
This makes the concept of an instantaneous frequency impossible <span class="citation">[<a href="#ref-grochenig2001" role="doc-biblioref">15</a>]</span>.</p>
<p>A direct result of the uncertainty principle is the fact that high temporal resolution
and frequency resolution cannot be acheived at the same time.</p>
<div class="figure">
<img src="img/stft_resolution.png" alt="" />
<p class="caption">STFT resolution with respect to different window sizes <span class="math inline">\(\Delta T\)</span> and overlap ratios <span class="math inline">\(r\)</span></p>
</div>
<p>In the figure above, we see the influence of the window size and the overlap ratio on the
STFT resolution.</p>
<ul>
<li><strong>Window size:</strong>
For larger window sizes, we have higher frequency resolution. However, the time resolution is low as we have fewer time samples for the STFT.
For smaller windows, we get higher time resolution as we have more time samples for the STFT, while losing frequency resolution due to smaller FT size.</li>
<li><strong>Overlap:</strong>
In the case of smaller overlaps, the resulting spectrum has time discontinuities. Indeed, the straight line appears to be a piece-wise constant function of time.
For overlap ratios close to 1, the time resolution is significantly better obtaining the best results (given an adequate window size). However, one should keep in mind that high overlaps can be computationally costly.</li>
</ul>
</div>
<div id="inverse-short-time-fourier-transform" class="section level3" number="3.3.6">
<h3><span class="header-section-number">3.3.6</span> Inverse Short-Time Fourier Transform</h3>
<p>The operator <span class="math inline">\(V_w\)</span> is an isometry from <span class="math inline">\(L^2(\mathbb{R})\)</span> to <span class="math inline">\(L^2(\mathbb{R}^2)\)</span>
if <span class="math inline">\(\left\lVert w\right\rVert_2=1\)</span>,
allowing for <span class="math inline">\(s\)</span> to be completely determined by <span class="math inline">\(V_w s\)</span>.
With the help of the orthogonality relations (Parseval’s formula) on the STFT we obtain
the inversion formula for the STFT (see Appendix <a href="6A_stft.html#istft">A</a> for a detailed proof).</p>
<p>For <span class="math inline">\(w,h\in L^2(\mathbb{R})\)</span> smooth windows such that <span class="math inline">\(\left\langle w,h\right\rangle\neq 0\)</span>
we have for all <span class="math inline">\(s\in L^2(\mathbb{R})\)</span>,</p>
<p><span class="math display">\[\begin{align}
s(t) &amp;=\frac{1}{\left\langle w,h\right\rangle} \iint_{\mathbb{R}^2}V_w s(\tau,\omega)M_\omega T_\tau h(t) \mathrm{d}\omega\mathrm{d}\tau\\
     &amp;= \frac{1}{\left\langle w,h\right\rangle}
        \iint_{\mathbb{R}^2} S(\tau,\omega) h(t-\tau) e^{2\pi i\omega t} \mathrm{d}\omega\mathrm{d}\tau
\end{align}\]</span></p>
</div>
<div id="griffin-lim-algorithm" class="section level3" number="3.3.7">
<h3><span class="header-section-number">3.3.7</span> Griffin-Lim Algorithm</h3>
<p>The practical use of the inverse STFT is to obtain the signal
from a spectrum that has undergone some changes.
Daniel W. Griffin and Jae S. Lim <span class="citation">[<a href="#ref-griffin1983" role="doc-biblioref">14</a>]</span> proposed
an efficient algorithm for signal estimation from the modified STFT.
The GLA algorithm minimizes the mean squared error between the STFT magnitude
of the estimated signal and the modified STFT magnitude.</p>
<p>This method is efficient and easy to implement, and is widely
used in signal processing libraries.</p>
<p>Let <span class="math inline">\(x\in L^2(\mathbb{R})\)</span> be a realizable signal and <span class="math inline">\(X=V_w x\in L^2(\mathbb{R}^2)\)</span>
be its STFT. Let <span class="math inline">\(Y\in L^2(\mathbb{R}^2)\)</span> denote the modified STFT.
It’s worth noting that <span class="math inline">\(Y\)</span>, in general, is not necessarily an STFT
in the sense that there might not be a signal <span class="math inline">\(y\in L^2(\mathbb{R})\)</span>
whose STFT is <span class="math inline">\(Y=V_w y\)</span> <span class="citation">[<a href="#ref-griffin1983" role="doc-biblioref">14</a>]</span>.</p>
<p>Let <span class="math inline">\(y_\tau \in L^2(\mathbb{R}^2)\)</span> the inverse Fourier transform of <span class="math inline">\(Y\)</span>
with respect to the frequency <span class="math inline">\(\omega\)</span> (its second variable)
at a fixed time <span class="math inline">\(\tau\in\mathbb{R}\)</span>.</p>
<p><span class="math display">\[\begin{equation}
y_\tau(t) = \int_{\mathbb{R}} Y(\tau,\omega) e^{2\pi i\omega t} \mathrm{d}\omega
\end{equation}\]</span></p>
<p>The algorithm finds iteratively the signal <span class="math inline">\(x\)</span> that minimizes
the distance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The distance measure between
the two spectrums is defined as the norm of the difference
over the <span class="math inline">\(L^2(\mathbb{R}^2)\)</span> space</p>
<p><span class="math display">\[\begin{equation}
d(X,Y) = \left\lVert X-Y\right\rVert_2^2
    = \iint_{\mathbb{R}^2} \left\lvert X(\tau,\omega) - Y(\tau,\omega)\right\rvert^2 \mathrm{d}\omega\mathrm{d}\tau
\end{equation}\]</span></p>
<p>Which is expressed for discrete STFT as
<span class="math display">\[\begin{equation}
d(X,Y) = \sum_\tau \sum_\omega\left\lvert X[\tau,\omega] - Y[\tau,\omega]\right\rvert^2
\end{equation}\]</span></p>
<p>The signal <span class="math inline">\(x[t]\)</span> is therefore reconstructed iteratively along the formula
<span class="math display">\[\begin{equation}
x[t] = \frac{\sum\limits_\tau y_\tau[t]w[t-\tau]}{\sum\limits_\tau w^2[t-\tau]}
\end{equation}\]</span></p>
</div>
</div>
<div id="the-lift-to-the-augmented-space" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> The lift to the augmented space</h2>
<p>In order to study the Wilson-Cowan model for neural activations,
we need to have a 3D representation of the sound.
In this section we will explain how the STFT of the sound signal
is lifted into the <strong>contact space</strong> and explore the properties of this space.</p>
<div id="the-sound-chirpiness" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> The sound chirpiness</h3>
<p>The 3D representation of the image in the sub-Riemannian model of V1
was obtained by considering the <em>sensitivity to directions</em>
represented by an angle <span class="math inline">\(\theta\in P^1=\mathbb{R}/\pi\mathbb{Z}\)</span>.</p>
<p>We transpose this concept of sensitivity to directions
for sound signals to sensitivity to <em>instantaneous chirpiness</em>
that is the time derivative of the frequency <span class="math inline">\(\nu=\mathrm{d}\omega/\mathrm{d}\tau\)</span>.
The time derivative of the frequency is indeed the slope
of the tangent line in the sound spectrogram.
Hence establishing the bridge with the visual model.</p>
</div>
<div id="single-time-varying-frequency" class="section level3" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Single time-varying frequency</h3>
<p>As we study the sound through its instantaneous frequency and chirpiness,
we consider both the frequency and the chirpiness functions of time.
To properly define the lift, we consider the following single
time-varying frequency sound signal</p>
<p><span class="math display">\[\begin{equation}
s(t) = A\cdot\sin(\omega(t)t),\quad A\in\mathbb{R}
\end{equation}\]</span></p>
<p>The STFT of this signal can be therefore expressed as</p>
<p><span class="math display">\[\begin{equation}
S(\tau,\omega) = \frac{A}{2i}\left(\delta_0(\omega-\omega(\tau)) - \delta_0(\omega+\omega(\tau))\right)
\end{equation}\]</span></p>
<p>supposing the FT is normalized, where <span class="math inline">\(\delta_0\)</span> is the Dirac delta
distribution centered at 0.
Which means that <span class="math inline">\(S\)</span> is concentrated on the curves <span class="math inline">\(\tau\mapsto(\tau,\omega(\tau))\)</span>
and <span class="math inline">\(\tau\mapsto(\tau,-\omega(\tau))\)</span>.</p>
<div class="figure">
<img src="img/single_freq.png" style="width:25.0%" alt="" />
<p class="caption">The STFT the single time-varying frequency sound signal</p>
</div>
<p>So far, the sound signal is represented in the 2-dimensional space
by the parametric curve <span class="math inline">\(t\mapsto(t,\omega(t))\)</span>.
Nevertheless, we aim to lift our signal into the 3-dimensional <em>augmented space</em>
by adding the sensitivity to frequency variations <span class="math inline">\(\nu(t)=\mathrm{d}\omega(t)/\mathrm{d}t\)</span>.
Similarly, the lifted curve is parameterized as <span class="math inline">\(t\mapsto(t,\omega(t),\nu(t))\)</span> <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
</div>
<div id="control-system" class="section level3" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Control system</h3>
<p>We define the control to the chirpiness variable <span class="math inline">\(u(t)=\mathrm{d}\nu/\mathrm{d}t\)</span>,
we can therefore say that the curve <span class="math inline">\(t\mapsto(\tau(t),\omega(t),\nu(t))\)</span>
in the contact space is a lift of a planar curve if there exists
a control <span class="math inline">\(u(t)\)</span> such that</p>
<p><span class="math display">\[\begin{equation}
\frac{\mathrm{d}}{\mathrm{d}t}\begin{pmatrix}\tau\\\omega\\\nu\end{pmatrix} = \begin{pmatrix}1\\\nu\\0\end{pmatrix} + u(t)\begin{pmatrix}0\\0\\1\end{pmatrix}
\end{equation}\]</span></p>
<p>We define the system state vector as <span class="math inline">\(q=(\tau,\omega,\nu)\)</span>, the control system
can be written as
<span class="math display">\[\begin{equation}
\frac{\mathrm{d}}{\mathrm{d}t}q(t) = X_0(q(t)) + u(t) X_1(q(t))
\end{equation}\]</span></p>
<p>where <span class="math inline">\(X_0(q(t))\)</span> and <span class="math inline">\(X_1(q(t))\)</span> are two vector fields in <span class="math inline">\(\mathbb{R}^3\)</span> defined as</p>
<p><span class="math display">\[\begin{equation}
X_0\begin{pmatrix}\tau\\\omega\\\nu\end{pmatrix} = \begin{pmatrix}1\\\nu\\0\end{pmatrix},\quad 
X_1\begin{pmatrix}\tau\\\omega\\\nu\end{pmatrix} = \begin{pmatrix}0\\0\\1\end{pmatrix}
\end{equation}\]</span></p>
<p>The vector fields <span class="math inline">\(X_0\)</span> and <span class="math inline">\(X_1\)</span> generate the Heisenberg group,
and the space <span class="math inline">\(\left\{X_0+uX_1\vert u\in\mathbb{R}\right\}\)</span> is a line in the <span class="math inline">\(\mathbb{R}^3\)</span> <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
</div>
<div id="lift-to-the-contact-space" class="section level3" number="3.4.4">
<h3><span class="header-section-number">3.4.4</span> Lift to the contact space</h3>
<p>In the case of a general sound signal, each level line of the spectrogram
<span class="math inline">\(\left\lvert S\right\rvert(\tau,\omega)\)</span> is lifted to the contact space.
This yeilds by the implicit function theorem the following subset
of the contact space, which is a well-defined surface
if <span class="math inline">\(\left\lvert S\right\rvert\in\mathcal{C}^2\)</span> and <span class="math inline">\(\mathrm{Hess}\left\lvert S\right\rvert\)</span> is non-degenerate <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
<p><span class="math display">\[\begin{equation}
\Sigma = \left\{(\tau,\omega,\nu)\in\mathbb{R}^3 \vert\nu\partial_\omega\left\lvert S\right\rvert(\tau,\omega) + \partial_\tau\left\lvert S\right\rvert(\tau,\omega) = 0\right\}
\end{equation}\]</span></p>
<p>Which allows to finally define the sound lift in the contact space as</p>
<p><span class="math display">\[\begin{equation}
L(\tau,\omega,\nu) = S(\tau,\omega)\cdot\delta_\Sigma (\tau,\omega,\nu) =
\begin{cases}
S(\tau,\omega) &amp; \text{if}~(\tau,\omega,\nu)\in\Sigma\\
0          &amp; \text{otherwise}
\end{cases}
\end{equation}\]</span></p>
<p>The time-frequency representation is obtained from the lifted sound
by applying the projection operator defined as</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Proj}\left\{L(\tau,\omega,\nu)\right\}(\tau,\omega) = \int_\mathbb{R}L(\tau,\omega,\nu)\mathrm{d}\nu
\end{equation}\]</span></p>
</div>
<div id="lift-implementation" class="section level3" number="3.4.5">
<h3><span class="header-section-number">3.4.5</span> Lift implementation</h3>
<p>We have seen that the lift to the contact space is defined through
the surface <span class="math inline">\(\Sigma\)</span> which is defined with respect to <span class="math inline">\(\nabla\left\lvert S\right\rvert\)</span>.
The chirpiness is numerically calculated by numerically approximating
the gradient of the spectrum <span class="math inline">\(\left\lvert S\right\rvert\)</span>.</p>
<p>The discretization of the time and frequency domains is determined by
the sampling rate of the original signal and the window size
chosen in the STFT procedure.
That is, by the Nyquist-Shannon sampling theorem,
for a temporal sampling rate <span class="math inline">\(\delta t\)</span> and a window size of <span class="math inline">\(T_w\)</span>,
we consider the frequencies <span class="math inline">\(\omega\)</span> such that <span class="math inline">\(|\omega|&lt;1/(2\delta t)\)</span>,
with a finest discretization rate of <span class="math inline">\(1/(2T_w)\)</span>.</p>
<p>The frequency domain is therefore bounded.
Nevertheless, the chirpiness <span class="math inline">\(\nu\)</span> defined as
<span class="math inline">\(\nu\partial_\omega\left\lvert S\right\rvert(\tau,\omega) + \partial_\tau\left\lvert S\right\rvert(\tau,\omega)=0\)</span> is unbounded,
and since generically there exists points such that
<span class="math inline">\(\partial_\omega\left\lvert S\right\rvert(\tau_0,\omega_0)=0\)</span>,
chirpiness values stretch over the entire real line.</p>
<p>To overcome this problem, a natural strategy is to model the chirpiness values as
a random variable <span class="math inline">\(X\)</span>, and considering only chirpinesses falling inside the confidence
interval <span class="math inline">\(I_p\)</span> for some reasonable <span class="math inline">\(p\)</span>-value (e.g., <span class="math inline">\(p=0.95\)</span>).
The best fit for the chirpiness values was the random variable <span class="math inline">\(X\)</span>
following a Cauchy distribution <span class="math inline">\(\mathrm{Cauchy}(x_0,\gamma)\)</span> <span class="citation">[<a href="#ref-asswad2021" role="doc-biblioref">4</a>]</span> where</p>
<ul>
<li><span class="math inline">\(x_0\)</span> is the location parameter that corresponds to the location of the peak</li>
<li><span class="math inline">\(\gamma\)</span> is the scale parameter that determines the shape of the distribution</li>
</ul>
<div class="figure">
<img src="img/cauchy_dist_pdf.png" alt="" />
<p class="caption">Chirpiness of a speech signal compared to Cauchy distribution</p>
</div>
<p>The Cauchy distribution’s probability density function (PDF) is given as
<span class="math display">\[\begin{equation}
f_X(x)=\frac{1}{\pi\gamma\left(1+\left(\frac{x-x_0}{\gamma}\right)^2\right)}
\end{equation}\]</span>
and it’s cumulative distribution function (CDF) is
<span class="math display">\[\begin{equation}
F_X(x)=\frac{1}{\pi} \arctan\left(\frac{x-x_0}{\gamma}\right) + \frac{1}{2}
\end{equation}\]</span></p>
<p>The Cauchy parameters were estimated as follows:</p>
<ul>
<li><span class="math inline">\(x_0\)</span>: the chirpiness samples median</li>
<li><span class="math inline">\(\gamma\)</span>: half the interquartile range which is the difference between
the 75<sup>th</sup> and the 25<sup>th</sup> percentile.</li>
</ul>
<p>Although statistical tests on a library of real-world speech
signals<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>
rejected the assumption that <span class="math inline">\(X\sim \mathrm{Cauchy}(x_0,\gamma)\)</span>,
the fit is quite good according to the Kolmogorov-Smirnov statistic
<span class="math display">\[\begin{equation}
D_n=\sup_x\left\lvert F_n(x)-F_X(x)\right\rvert
\end{equation}\]</span>
where <span class="math inline">\(F_n\)</span> is the empirical distribution function
evaluated over the chirpiness values <span class="citation">[<a href="#ref-asswad2021" role="doc-biblioref">4</a>]</span>.</p>
<p><img src="img/cauchy_pt_estimate_iqr_2.png" width="100" class="inline" style="margin-left: 300px;">
<img src="img/cauchy_values_percentage_iqr_2.png" width="100" class="inline"></p>
<p class="caption">
Box plots for estimated Cauchy distributions of speech signals chirpiness.
<em>Left:</em> Kolmogorov-Smirnov statistic values.
<em>Right:</em> percentage of values falling in <span class="math inline"><span class="math inline">\(I_{0.95}\)</span></span>
</p>
</div>
</div>
<div id="cortical-activations-in-a1" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Cortical activations in A1</h2>
<p>In this model, we consider the primary auditory cortex (A1) as the space of <span class="math inline">\((\omega,\nu)\in\mathbb{R}^2\)</span>.
When hearing a sound signal <span class="math inline">\(s\)</span>, A1 receives its lift to the contact space <span class="math inline">\(L(t,\omega,\nu)\)</span>
at every instant <span class="math inline">\(t\)</span>.
The <em>neuron</em> receives an external charge <span class="math inline">\(S(t,\omega)\)</span> if <span class="math inline">\((t,\omega,\nu)\in\Sigma\)</span> and no charge otherwise.</p>
<p>The Wilson-Cowan equations (WC) <span class="citation">[<a href="#ref-wilson1972" role="doc-biblioref">27</a>]</span> have been successfully applied to describe
the evolution of neural activations in V1 as well as A1
<span class="citation">[<a href="#ref-bertalmio2018" role="doc-biblioref">5</a>,<a href="#ref-boscain2017" role="doc-biblioref">6</a>,<a href="#ref-bressloff2002a" role="doc-biblioref">9</a>,<a href="#ref-ermentrout1979" role="doc-biblioref">13</a>,<a href="#ref-loebel2007" role="doc-biblioref">19</a>,<a href="#ref-rankin2015" role="doc-biblioref">23</a>,<a href="#ref-zulfiqar2019" role="doc-biblioref">29</a>]</span>.</p>
<p>The WC equations have the advantage of being flexible as they can be applied independently
of the underlying geometric structure, which is only encoded in the kernel of the integral term.
They allow as well for a natural implementation of delay terms in the interactions
and can be easily tuned via few parameters with clear effect on the results.</p>
<p>In this model, the resulting activation <span class="math inline">\(a:[0,T]\times\mathbb{R}\times\mathbb{R}\rightarrow\mathbb{C}\)</span> is the solution
to the WC differo-integral equation with a delay <span class="math inline">\(\delta\)</span>.</p>
<p><span class="math display">\[\begin{equation}
\frac{\partial}{\partial t}a(t,\omega,\nu) = -\alpha a(t,\omega,\nu) + \beta L(t,\omega,\nu)
+ \gamma\int_{\mathbb{R}^2} k_\delta(\omega,\nu\Vert\omega&#39;,\nu&#39;) \sigma(a(t-\delta,\omega&#39;,\nu&#39;)) \mathrm{d}\omega&#39;\mathrm{d}\nu&#39;
\end{equation}\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\alpha,\beta,\gamma&gt;0\)</span> are parameters</li>
<li><span class="math inline">\(\sigma:\mathbb{C}\rightarrow\mathbb{C}\)</span> is a non-linear sigmoid where <span class="math inline">\(\sigma(\rho e^{i\theta})=\tilde\sigma(\rho)e^{i\theta}\)</span>
with <span class="math inline">\(\tilde\sigma(x)=\min\left\{\max\left\{0,\kappa x\right\}, 1\right\},\forall x\in\mathbb{R}\)</span> given a fixed <span class="math inline">\(\kappa&gt;0\)</span>.</li>
<li><span class="math inline">\(k_\delta(\omega,\nu\Vert\omega&#39;,\nu&#39;)\)</span> is a weight modeling the interaction
between <span class="math inline">\((\omega,\nu)\)</span> and <span class="math inline">\((\omega&#39;,\nu&#39;)\)</span> after a delay <span class="math inline">\(\delta&gt;0\)</span> via the kernel of the transport-diffusion
operator associated to the contact structure of A1.</li>
</ul>
<p>When <span class="math inline">\(\gamma=0\)</span>, the WC equation becomes a standard low-pass filter <span class="math inline">\(\partial_t a=-\alpha a + L\)</span>
whose solution is simply</p>
<p><span class="math display">\[\begin{equation}
a(t,\omega,\nu) = \int_0^t e^{-\alpha(s-t)}L(t,\omega,\nu)\mathrm{d}s
\end{equation}\]</span></p>
<p>With <span class="math inline">\(\gamma\neq0\)</span>, a non-linear delayed interaction term is added on top
of the low-pass filter, encoding the inhibitory and excitatory interconnections between neurons <span class="citation">[<a href="#ref-boscain2021" role="doc-biblioref">7</a>]</span>.</p>
<p>In the scope of the internship, no work was carried on the integral kernel.
Hence, no further explanation on the WC model is needed.</p>
<div style="page-break-after: always;"></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body">
<div id="ref-asswad2021" class="csl-entry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">Rand Asswad, Ugo Boscain, Giuseppina Turco, Dario Prandi, and Ludovic Sacchelli. 2021. An <span>Auditory</span> <span>Cortex</span> <span>Model</span> for <span>Sound</span> <span>Processing</span>. 56–64. DOI:https://doi.org/<a href="https://doi.org/10.1007/978-3-030-80209-7_7">10.1007/978-3-030-80209-7_7</a></div>
</div>
<div id="ref-bertalmio2018" class="csl-entry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">Marcelo Bertalmío, Luca Calatroni, Valentina Franceschi, Benedetta Franceschiello, and Dario Prandi. 2018. A cortical-inspired model for orientation-dependent contrast perception: A link with <span>Wilson</span>-<span>Cowan</span> equations. <em>arXiv:1812.07425 [cs]</em> (December 2018). Retrieved November 12, 2020 from <a href="http://arxiv.org/abs/1812.07425">http://arxiv.org/abs/1812.07425</a></div>
</div>
<div id="ref-boscain2017" class="csl-entry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">Ugo Boscain, Roman Chertovskih, Jean-Paul Gauthier, Dario Prandi, and Alexey Remizov. 2017. Cortical-inspired image reconstruction via sub-<span>Riemannian</span> geometry and hypoelliptic diffusion. In <em><span>SMAI</span> 2017 - 8e <span>Biennale</span> <span>Française</span> des <span>Mathématiques</span> <span>Appliquées</span> et <span>Industrielles</span></em>, La Tremblade, France, 37–53. DOI:https://doi.org/<a href="https://doi.org/10.1051/proc/201864037">10.1051/proc/201864037</a></div>
</div>
<div id="ref-boscain2021" class="csl-entry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">Ugo Boscain, Dario Prandi, Ludovic Sacchelli, and Giuseppina Turco. 2021. A bio-inspired geometric model for sound reconstruction. <em>The Journal of Mathematical Neuroscience</em> 11, 1 (January 2021), 2. DOI:https://doi.org/<a href="https://doi.org/10.1186/s13408-020-00099-4">10.1186/s13408-020-00099-4</a></div>
</div>
<div id="ref-bressloff2002a" class="csl-entry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">Paul C. Bressloff, Jack D. Cowan, Martin Golubitsky, Peter J. Thomas, and Matthew C. Wiener. 2002. What <span>Geometric</span> <span>Visual</span> <span>Hallucinations</span> <span>Tell</span> <span>Us</span> about the <span>Visual</span> <span>Cortex</span>. <em>Neural Computation</em> 14, 3 (March 2002), 473–491. DOI:https://doi.org/<a href="https://doi.org/10.1162/089976602317250861">10.1162/089976602317250861</a></div>
</div>
<div id="ref-dallos1996" class="csl-entry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">P. Dallos. 1996. Overview: <span>Cochlear</span> <span>Neurobiology</span>: <span>Springer</span> <span>Handbook</span> of <span>Auditory</span> <span>Research</span>. <em>The Cochlea: Springer Handbook of Auditory Research</em> (1996), 1–43. Retrieved August 13, 2021 from <a href="https://www.scholars.northwestern.edu/en/publications/overview-cochlear-neurobiology-springer-handbook-of-auditory-rese">https://www.scholars.northwestern.edu/en/publications/overview-cochlear-neurobiology-springer-handbook-of-auditory-rese</a></div>
</div>
<div id="ref-ermentrout1979" class="csl-entry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">G. B. Ermentrout and J. D. Cowan. 1979. A mathematical theory of visual hallucination patterns. <em>Biological Cybernetics</em> 34, 3 (October 1979), 137–150. DOI:https://doi.org/<a href="https://doi.org/10.1007/BF00336965">10.1007/BF00336965</a></div>
</div>
<div id="ref-griffin1983" class="csl-entry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">D. Griffin and Jae S. Lim. 1983. Signal estimation from modified short-time <span>Fourier</span> transform. <em>undefined</em> (1983). Retrieved September 3, 2021 from <a href="https://www.semanticscholar.org/paper/Signal-estimation-from-modified-short-time-Fourier-Griffin-Lim/14bc876fae55faf5669beb01667a4f3bd324a4f1">https://www.semanticscholar.org/paper/Signal-estimation-from-modified-short-time-Fourier-Griffin-Lim/14bc876fae55faf5669beb01667a4f3bd324a4f1</a></div>
</div>
<div id="ref-grochenig2001" class="csl-entry">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">Karlheinz Gröchenig. 2001. <em>Foundations of <span>Time</span>-<span>Frequency</span> <span>Analysis</span></em>. Birkhäuser Basel. DOI:https://doi.org/<a href="https://doi.org/10.1007/978-1-4612-0003-1">10.1007/978-1-4612-0003-1</a></div>
</div>
<div id="ref-heinzel2002" class="csl-entry">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">Gerhard Heinzel, Albrecht Rüdiger, and Roland Schilling. 2002. Spectrum and spectral density estimation by the <span>Discrete</span> <span>Fourier</span> transform (<span>DFT</span>), including a comprehensive list of window functions and some new at-top windows. (2002). Retrieved September 9, 2021 from <a href="https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_152164">https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_152164</a></div>
</div>
<div id="ref-loebel2007" class="csl-entry">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">Alex Loebel, Israel Nelken, and Misha Tsodyks. 2007. Processing of sounds by population spikes in a model of primary auditory cortex. <em>Frontiers in Neuroscience</em> 1, 1 (November 2007), 197–209. DOI:https://doi.org/<a href="https://doi.org/10.3389/neuro.01.1.1.015.2007">10.3389/neuro.01.1.1.015.2007</a></div>
</div>
<div id="ref-muller2015" class="csl-entry">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">Meinard Müller. 2015. <em>Fundamentals of <span>Music</span> <span>Processing</span> - <span>Audio</span>, <span>Analysis</span>, <span>Algorithms</span>, <span>Applications</span></em>. Springer. Retrieved from <a href="https://www.audiolabs-erlangen.de/fau/professor/mueller/bookFMP">https://www.audiolabs-erlangen.de/fau/professor/mueller/bookFMP</a></div>
</div>
<div id="ref-rankin2015" class="csl-entry">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">James Rankin, Elyse Sussman, and John Rinzel. 2015. Neuromechanistic <span>Model</span> of <span>Auditory</span> <span>Bistability</span>. <em>PLoS computational biology</em> 11, 11 (November 2015), e1004555. DOI:https://doi.org/<a href="https://doi.org/10.1371/journal.pcbi.1004555">10.1371/journal.pcbi.1004555</a></div>
</div>
<div id="ref-roads2002" class="csl-entry">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">Curtis Roads. 2002. Microsound. (March 2002). DOI:https://doi.org/<a href="https://doi.org/10.7551/mitpress/4601.001.0001">10.7551/mitpress/4601.001.0001</a></div>
</div>
<div id="ref-sen2014" class="csl-entry">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">Debashis Sen. 2014. The uncertainty relations in quantum mechanics. <em>Current science</em> 107, (July 2014), 203–218. DOI:https://doi.org/<a href="https://doi.org/10.13140/2.1.5183.0406">10.13140/2.1.5183.0406</a></div>
</div>
<div id="ref-wilson1972" class="csl-entry">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">Hugh R. Wilson and Jack D. Cowan. 1972. Excitatory and <span>Inhibitory</span> <span>Interactions</span> in <span>Localized</span> <span>Populations</span> of <span>Model</span> <span>Neurons</span>. <em>Biophysical Journal</em> 12, 1 (January 1972), 1–24. DOI:https://doi.org/<a href="https://doi.org/10.1016/S0006-3495(72)86068-5">10.1016/S0006-3495(72)86068-5</a></div>
</div>
<div id="ref-yang1992" class="csl-entry">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">Xiaowei Yang, Kuansan Wang, and Shihab Shamma. 1992. Auditory representations of acoustic signals. <em>Information Theory, IEEE Transactions on</em> 38, (April 1992), 824–839. DOI:https://doi.org/<a href="https://doi.org/10.1109/18.119739">10.1109/18.119739</a></div>
</div>
<div id="ref-zulfiqar2019" class="csl-entry">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">Isma Zulfiqar, Michelle Moerel, and Elia Formisano. 2019. Spectro-<span>Temporal</span> <span>Processing</span> in a <span>Two</span>-<span>Stream</span> <span>Computational</span> <span>Model</span> of <span>Auditory</span> <span>Cortex</span>. <em>Frontiers in Computational Neuroscience</em> 13, (2019), 95. DOI:https://doi.org/<a href="https://doi.org/10.3389/fncom.2019.00095">10.3389/fncom.2019.00095</a></div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The speech material used in the current study is part of an ongoing
psycholinguistic project on spoken word recognition.
Speech material comprises 49 Italian words and 118 French words.
The two sets of words were produced by two (40-year-old) female speakers
(a French monolingual speaker and an Italian monolingual speaker) and recorded
using a headset microphone AKG C 410 and a Roland Quad Capture audio interface.
Recordings took place in the soundproof cabin of the Laboratoire de Phonétique
et Phonologie (LPP) of Université de Paris Sorbonne-Nouvelle.
Both informants were told to read the set of words as fluently and naturally as possible<a href="3_WCA1.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="2_WCV1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4_implementation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": {}
},
"fontsettings": false,
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": [["book.pdf", "PDF"]],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
